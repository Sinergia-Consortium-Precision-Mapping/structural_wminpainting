{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src import utils\n",
    "from src.utils import *\n",
    "\n",
    "from src import plot_utils\n",
    "from src import graph_utils\n",
    "from src import inpaint_utils\n",
    "from src import fiberatlas_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "The goal of this notebook is to do inpainting. Allowing for negative weightings of bundle to generate bundles, and allowing as well negatively connected bundles to exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 3\n",
    "connFilename = f'../../atlas_data/fiber_atlas/probconnatlas/wm.connatlas.scale{scale}.h5'\n",
    "hf = h5py.File(connFilename, 'r')\n",
    "\n",
    "centers = np.array(hf.get('header').get('gmcoords'))\n",
    "nsubject = hf.get('header').get('nsubjects')[()]\n",
    "dim = hf.get('header').get('dim')[()]\n",
    "fiber_affine = hf.get('header').get('affine')[()]\n",
    "\n",
    "gmregions_names = hf.get('header').get('gmregions')[()]\n",
    "nb_regions = gmregions_names.shape[0]\n",
    "\n",
    "gm_mask_subj = nib.load('../../atlas_data/moviedata_fMRI_eg/gm_mask_subj7.nii').get_fdata() \n",
    "wm_mask_subj = (gm_mask_subj + 1) % 2\n",
    "\n",
    "\n",
    "consistency_view = fiberatlas_utils.get_aggprop(hf, 'consistency')\n",
    "length_view = fiberatlas_utils.get_aggprop(hf, 'length')\n",
    "nbStlines_view = fiberatlas_utils.get_aggprop(hf, 'numbStlines')\n",
    "nb_regions = consistency_view.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressing Bundle Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: consider bundles that appear at least in 30 % of the subjects\n",
    "thresh_subjapp = int(np.ceil(nsubject * 0.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [46:55<00:00, 11.59s/it]   \n"
     ]
    }
   ],
   "source": [
    "# GENERATING ORIGINAL - without caring about voxel percentage\n",
    "# Generating the X samples and the y samples\n",
    "# 1. Careful as well to remove the auto-correlation in the diagonal\n",
    "# 2. Raster scan parsing meaning that it is the activity of (R0,R1) -> (R0,R2) -> (R0,R3) etc...\n",
    "# Define matrix of end points on cortex\n",
    "X = []\n",
    "bundles_labels = []\n",
    "for i in tqdm(range(1,nb_regions + 1)):\n",
    "    for j in range(i,nb_regions + 1):\n",
    "        tmp = fiberatlas_utils.get_bundles_betweenreg(hf, i, j, verbose=False)\n",
    "        if tmp is None: continue\n",
    "        if np.sum(tmp[:,3] >= (thresh_subjapp)) == 0: continue\n",
    "        bundles_labels.append((i,j))\n",
    "        vec = np.zeros(nb_regions)\n",
    "        vec[i-1] = 1.0\n",
    "        vec[j-1] = 1.0\n",
    "        X.append(vec)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 108/243 [15:45<11:51,  5.27s/it]/var/folders/9t/60tqjhtx2h55525lstv8nsc40000gn/T/ipykernel_59200/2900515649.py:24: RuntimeWarning: Mean of empty slice.\n",
      "  bproba_i = bundle_proba_i[bundle_proba_i!=0].mean()\n",
      "/Users/mikichan/miniconda3/envs/microstruct_atlasing/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 243/243 [1:03:44<00:00, 15.74s/it]  \n"
     ]
    }
   ],
   "source": [
    "root = '../../atlas_data/fiber_atlas/yasser_datacomp/volspams_compress/'\n",
    "\n",
    "atlas_of_interest = f'compresslausanne2018.scale{scale}.sym.corrected.ctx+subc.volspams.nii.gz'\n",
    "\n",
    "prob_regions, prob_affine = (nib.load(root + atlas_of_interest).get_fdata()[:,:,:,1:], \n",
    "                             nib.load(root + atlas_of_interest).affine)\n",
    "\n",
    "Xp = []\n",
    "bundles_labels = []\n",
    "for i in tqdm(range(1,nb_regions + 1)):\n",
    "    for j in range(i,nb_regions + 1):\n",
    "        tmp = fiberatlas_utils.get_bundles_betweenreg(hf, i, j, verbose=False)\n",
    "        if tmp is None: continue\n",
    "        if np.sum(tmp[:,3] >= (thresh_subjapp)) == 0: continue\n",
    "        bundle_coords = tmp[:,[0,1,2]]\n",
    "\n",
    "        prob_vox = np.zeros_like(prob_regions[:,:,:,0])\n",
    "        prob_vox[bundle_coords[:,0], bundle_coords[:,1], bundle_coords[:,2]] = 1.0\n",
    "\n",
    "        region_i = prob_regions[:,:,:,i-1]\n",
    "        region_j = prob_regions[:,:,:,j-1]\n",
    "\n",
    "        bundle_proba_i = (region_i * prob_vox)\n",
    "        bproba_i = bundle_proba_i[bundle_proba_i!=0].mean()\n",
    "        bundle_proba_j = (region_j * prob_vox)\n",
    "        bproba_j = bundle_proba_j[bundle_proba_j!=0].mean()\n",
    "\n",
    "        bundles_labels.append((i,j))\n",
    "        vec = np.zeros(nb_regions)\n",
    "        vec[i-1] = bproba_i\n",
    "        vec[j-1] = bproba_j\n",
    "        Xp.append(vec)\n",
    "\n",
    "Xp = np.array(Xp)\n",
    "Xp = np.nan_to_num(Xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_ftimecourse = load(f\"../../atlas_data/moviedata_fMRI_eg/yasseratlased_fmri/ftimecourse_95_scale{scale}.pkl\")\n",
    "regions_in_voxels = load(f'../../atlas_data/fiber_atlas/regions95_voxels_scale{scale}.pkl')[:,:,:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [50:34<00:00, 252.89s/it]\n",
      "100%|██████████| 12/12 [10:15<00:00, 51.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# Regressing with L1-L2\n",
    "regularizers = np.sort(np.concatenate([np.logspace(0,5,6), np.logspace(0,5,6) / 2]))\n",
    "\n",
    "perf_ridge = {'coefs': [],'scores': [], 'intercepts': []}\n",
    "for k in tqdm(range(len(regularizers))):\n",
    "    coefs, scores, intercepts = inpaint_utils.regress_linear(X, region_ftimecourse, \n",
    "                                                            regularizers[k], ridgeflag=True, verbose=False)\n",
    "    perf_ridge['coefs'].append(coefs)\n",
    "    perf_ridge['scores'].append(scores)\n",
    "    perf_ridge['intercepts'].append(intercepts)\n",
    "\n",
    "perf_lasso = {'coefs': [],'scores': [], 'intercepts': []}\n",
    "for k in tqdm(range(len(regularizers))):\n",
    "    coefs, scores, intercepts = inpaint_utils.regress_linear(X, region_ftimecourse, \n",
    "                                                            regularizers[k], ridgeflag=False, verbose=False)\n",
    "    perf_lasso['coefs'].append(coefs)\n",
    "    perf_lasso['scores'].append(scores)\n",
    "    perf_lasso['intercepts'].append(intercepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(f\"../resources/weights_regressors_activity/weighted_bundle_activity_lasso{thresh_subjapp}_scale{scale}.pkl\", perf_lasso)\n",
    "save(f\"../resources/weights_regressors_activity/weighted_bundle_activity_ridge{thresh_subjapp}_scale{scale}.pkl\", perf_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial graph defining\n",
    "bundle_graph = np.zeros((X.shape[0], X.shape[0]))\n",
    "for k in range(X.shape[0]):\n",
    "    avect1 = X[k]\n",
    "    for s in range(X.shape[0]):\n",
    "        if s == k: continue\n",
    "        avect2 = X[s]\n",
    "        if np.abs(avect1 - avect2).sum() <= 2:\n",
    "            bundle_graph[k,s] = 1.0\n",
    "            bundle_graph[s,k] = 1.0\n",
    "\n",
    "# temporal graph defining\n",
    "cycle = graph_utils.make_cycle(region_ftimecourse.shape[-1])\n",
    "\n",
    "Ls = graph_utils.compute_directed_laplacian(bundle_graph)\n",
    "Lt = graph_utils.compute_directed_laplacian(cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmult = np.array([Xp.T for _ in range(region_ftimecourse.shape[-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [9:27:55<00:00, 170.38s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses are decomposed into:\n",
      "generic loss=tensor([0.7468])\n",
      "spatialloss=tensor([10657166.])\n",
      "temporalloss=tensor([12104.2012])\n",
      "sumloss=tensor([0.7468])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:14:52<00:00, 22.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses are decomposed into:\n",
      "generic loss=tensor([12787.6006])\n",
      "spatialloss=tensor([3107269.])\n",
      "temporalloss=tensor([5381.7168])\n",
      "sumloss=tensor([43914.1055])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:13:51<00:00, 22.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses are decomposed into:\n",
      "generic loss=tensor([78745.2969])\n",
      "spatialloss=tensor([374045.])\n",
      "temporalloss=tensor([1893.4266])\n",
      "sumloss=tensor([116339.1406])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:29:33<00:00, 26.87s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses are decomposed into:\n",
      "generic loss=tensor([86394.8359])\n",
      "spatialloss=tensor([388395.1562])\n",
      "temporalloss=tensor([1479.9309])\n",
      "sumloss=tensor([476269.9375])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:11:37<00:00, 21.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses are decomposed into:\n",
      "generic loss=tensor([92826.6953])\n",
      "spatialloss=tensor([388430.1562])\n",
      "temporalloss=tensor([669.5716])\n",
      "sumloss=tensor([3983824.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:41:27<00:00, 30.44s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses are decomposed into:\n",
      "generic loss=tensor([108807.9062])\n",
      "spatialloss=tensor([388880.9688])\n",
      "temporalloss=tensor([483.9220])\n",
      "sumloss=tensor([39045296.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ps = [(0,0), (1e-2,1e-2), (1e-1,1e-1), (1,1), (10,10), (100,100)]\n",
    "for (p1,p2) in ps:\n",
    "    bundle_opt, logs = inpaint_utils.optimize_lreg(Xmult, region_ftimecourse, Ls=Ls, Lt=Lt, \n",
    "                                               verbose=True, num_epochs=200, logging=True, p1=p1, p2=p2, lr=1)\n",
    "\n",
    "    save(f\"../resources/weights_regressors_activity/weighted_bundle_activity_timevertex{thresh_subjapp}_scale{scale}_p1-{p1}_p2-{p2}.pkl\", bundle_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Close the opened h5 file\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
