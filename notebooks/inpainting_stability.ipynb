{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src import utils\n",
    "from src.utils import *\n",
    "\n",
    "\n",
    "from src import plot_utils\n",
    "from src import graph_utils\n",
    "from src import inpaint_utils\n",
    "from src import fiberatlas_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "The goal of this notebook is to do create paths (voxel level) to match pairs of regions with highest connectivity paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Generate paths according to the functional connectivity of pairs of regions. \n",
    "- E.g using highest sum of energy (energy being positive correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate usual bundle paths prior to optimization and prepare functional connectivity information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1\n",
    "connFilename = f'../../atlas_data/fiber_atlas/probconnatlas/wm.connatlas.scale{scale}.h5'\n",
    "hf = h5py.File(connFilename, 'r')\n",
    "\n",
    "centers = np.array(hf.get('header').get('gmcoords'))\n",
    "nsubject = hf.get('header').get('nsubjects')[()]\n",
    "dim = hf.get('header').get('dim')[()]\n",
    "fiber_affine = hf.get('header').get('affine')[()]\n",
    "\n",
    "gmregions_names = hf.get('header').get('gmregions')[()]\n",
    "nb_regions = gmregions_names.shape[0]\n",
    "\n",
    "gm_mask_subj = nib.load('../../atlas_data/moviedata_fMRI_eg/gm_mask_subj7.nii').get_fdata() \n",
    "wm_mask_subj = (gm_mask_subj + 1) % 2\n",
    "\n",
    "\n",
    "consistency_view = fiberatlas_utils.get_aggprop(hf, 'consistency')\n",
    "length_view = fiberatlas_utils.get_aggprop(hf, 'length')\n",
    "nbStlines_view = fiberatlas_utils.get_aggprop(hf, 'numbStlines')\n",
    "nb_regions = consistency_view.shape[0]\n",
    "\n",
    "# NOTE: consider bundles that appear at least in 30 % of the subjects\n",
    "thresh_subjapp = int(np.ceil(nsubject * 0.1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No fibers Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:30<00:00,  3.10it/s]\n",
      " 36%|███▌      | 34/95 [03:23<05:53,  5.80s/it]/tmp/ipykernel_49412/1155933020.py:47: RuntimeWarning: Mean of empty slice.\n",
      "  bproba_i = bundle_proba_i[bundle_proba_i!=0].mean()\n",
      "/home/chchan/miniconda3/envs/microstruct_atlas/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 95/95 [06:38<00:00,  4.19s/it]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]/home/chchan/miniconda3/envs/microstruct_atlas/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100%|██████████| 200/200 [00:57<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses are decomposed into:\n",
      "generic loss=tensor([1.8552])\n",
      "spatialloss=tensor([2965809.2500])\n",
      "temporalloss=tensor([14861.0010])\n",
      "sumloss=tensor([1.8552])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "bundles_labels = []\n",
    "for i in tqdm(range(1,nb_regions + 1)):\n",
    "    for j in range(i,nb_regions + 1):\n",
    "        tmp = fiberatlas_utils.get_bundles_betweenreg(hf, i, j, verbose=False)\n",
    "        if tmp is None: continue\n",
    "        if np.sum(tmp[:,3] >= (thresh_subjapp)) == 0: continue\n",
    "        bundles_labels.append((i,j))\n",
    "        vec = np.zeros(nb_regions)\n",
    "        vec[i-1] = 1.0\n",
    "        vec[j-1] = 1.0\n",
    "        X.append(vec)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "root = '../../atlas_data/fiber_atlas/yasser_datacomp/volspams_compress/'\n",
    "\n",
    "atlas_of_interest = f'compresslausanne2018.scale{scale}.sym.corrected.ctx+subc.volspams.nii.gz'\n",
    "\n",
    "prob_regions, prob_affine = (nib.load(root + atlas_of_interest).get_fdata()[:,:,:,1:], \n",
    "                             nib.load(root + atlas_of_interest).affine)\n",
    "\n",
    "Xp = []\n",
    "bundles_labels = []\n",
    "for i in tqdm(range(1,nb_regions + 1)):\n",
    "    for j in range(i,nb_regions + 1):\n",
    "        tmp = fiberatlas_utils.get_bundles_betweenreg(hf, i, j, verbose=False)\n",
    "        if tmp is None: continue\n",
    "        if np.sum(tmp[:,3] >= (thresh_subjapp)) == 0: continue\n",
    "        bundle_coords = tmp[:,[0,1,2]]\n",
    "\n",
    "        prob_vox = np.zeros_like(prob_regions[:,:,:,0])\n",
    "        prob_vox[bundle_coords[:,0], bundle_coords[:,1], bundle_coords[:,2]] = 1.0\n",
    "\n",
    "        region_i = prob_regions[:,:,:,i-1]\n",
    "        region_j = prob_regions[:,:,:,j-1]\n",
    "\n",
    "        bundle_proba_i = (region_i * prob_vox)\n",
    "        bproba_i = bundle_proba_i[bundle_proba_i!=0].mean()\n",
    "        bundle_proba_j = (region_j * prob_vox)\n",
    "        bproba_j = bundle_proba_j[bundle_proba_j!=0].mean()\n",
    "\n",
    "        bundles_labels.append((i,j))\n",
    "        vec = np.zeros(nb_regions)\n",
    "        vec[i-1] = bproba_i\n",
    "        vec[j-1] = bproba_j\n",
    "        Xp.append(vec)\n",
    "\n",
    "Xp = np.array(Xp)\n",
    "Xp = np.nan_to_num(Xp)\n",
    "\n",
    "region_ftimecourse = load(f\"../../atlas_data/moviedata_fMRI_eg/yasseratlased_fmri/ftimecourse_95_scale{scale}.pkl\")\n",
    "regions_in_voxels = load(f'../../atlas_data/fiber_atlas/regions95_voxels_scale{scale}.pkl')[:,:,:,1:]\n",
    "\n",
    "# spatial graph defining\n",
    "bundle_graph = np.zeros((X.shape[0], X.shape[0]))\n",
    "for k in range(X.shape[0]):\n",
    "    avect1 = X[k]\n",
    "    for s in range(X.shape[0]):\n",
    "        if s == k: continue\n",
    "        avect2 = X[s]\n",
    "        if np.abs(avect1 - avect2).sum() <= 2:\n",
    "            bundle_graph[k,s] = 1.0\n",
    "            bundle_graph[s,k] = 1.0\n",
    "\n",
    "# temporal graph defining\n",
    "cycle = graph_utils.make_cycle(region_ftimecourse.shape[-1])\n",
    "\n",
    "Ls = graph_utils.compute_directed_laplacian(bundle_graph)\n",
    "Lt = graph_utils.compute_directed_laplacian(cycle)\n",
    "\n",
    "Xmult = np.array([Xp.T for _ in range(region_ftimecourse.shape[-1])])\n",
    "\n",
    "bundle_opt, logs = inpaint_utils.optimize_lreg(Xmult, region_ftimecourse, Ls=Ls, Lt=Lt, \n",
    "                                               verbose=True, num_epochs=200, logging=True, p1=0, p2=0, lr=1)\n",
    "\n",
    "save(f\"../resources/weights_regressors_activity/weighted_bundle_activity_timevertex{thresh_subjapp}_scale{scale}_stability-noremove.pkl\", bundle_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random fibers Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = 10\n",
    "np.random.seed(99)\n",
    "\n",
    "edges = np.array(np.where(consistency_view > 0)).T\n",
    "toremove = edges[np.random.choice(np.arange(len(edges)), len(edges)//10, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8284271247461903"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(np.linalg.norm(np.array([13,-1]) - toremove, axis=1)) < "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with 10% removed\n",
    "X = []\n",
    "bundles_labels = []\n",
    "for i in tqdm(range(1,nb_regions + 1)):\n",
    "    for j in range(i,nb_regions + 1):\n",
    "        tmp = fiberatlas_utils.get_bundles_betweenreg(hf, i, j, verbose=False)\n",
    "        if (i-1,j-1)\n",
    "        if tmp is None: continue\n",
    "        if np.sum(tmp[:,3] >= (thresh_subjapp)) == 0: continue\n",
    "        bundles_labels.append((i,j))\n",
    "        vec = np.zeros(nb_regions)\n",
    "        vec[i-1] = 1.0\n",
    "        vec[j-1] = 1.0\n",
    "        X.append(vec)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "root = '../../atlas_data/fiber_atlas/yasser_datacomp/volspams_compress/'\n",
    "\n",
    "atlas_of_interest = f'compresslausanne2018.scale{scale}.sym.corrected.ctx+subc.volspams.nii.gz'\n",
    "\n",
    "prob_regions, prob_affine = (nib.load(root + atlas_of_interest).get_fdata()[:,:,:,1:], \n",
    "                             nib.load(root + atlas_of_interest).affine)\n",
    "\n",
    "Xp = []\n",
    "bundles_labels = []\n",
    "for i in tqdm(range(1,nb_regions + 1)):\n",
    "    for j in range(i,nb_regions + 1):\n",
    "        tmp = fiberatlas_utils.get_bundles_betweenreg(hf, i, j, verbose=False)\n",
    "        if tmp is None: continue\n",
    "        if np.sum(tmp[:,3] >= (thresh_subjapp)) == 0: continue\n",
    "        bundle_coords = tmp[:,[0,1,2]]\n",
    "\n",
    "        prob_vox = np.zeros_like(prob_regions[:,:,:,0])\n",
    "        prob_vox[bundle_coords[:,0], bundle_coords[:,1], bundle_coords[:,2]] = 1.0\n",
    "\n",
    "        region_i = prob_regions[:,:,:,i-1]\n",
    "        region_j = prob_regions[:,:,:,j-1]\n",
    "\n",
    "        bundle_proba_i = (region_i * prob_vox)\n",
    "        bproba_i = bundle_proba_i[bundle_proba_i!=0].mean()\n",
    "        bundle_proba_j = (region_j * prob_vox)\n",
    "        bproba_j = bundle_proba_j[bundle_proba_j!=0].mean()\n",
    "\n",
    "        bundles_labels.append((i,j))\n",
    "        vec = np.zeros(nb_regions)\n",
    "        vec[i-1] = bproba_i\n",
    "        vec[j-1] = bproba_j\n",
    "        Xp.append(vec)\n",
    "\n",
    "Xp = np.array(Xp)\n",
    "Xp = np.nan_to_num(Xp)\n",
    "\n",
    "region_ftimecourse = load(f\"../../atlas_data/moviedata_fMRI_eg/yasseratlased_fmri/ftimecourse_95_scale{scale}.pkl\")\n",
    "regions_in_voxels = load(f'../../atlas_data/fiber_atlas/regions95_voxels_scale{scale}.pkl')[:,:,:,1:]\n",
    "\n",
    "# spatial graph defining\n",
    "bundle_graph = np.zeros((X.shape[0], X.shape[0]))\n",
    "for k in range(X.shape[0]):\n",
    "    avect1 = X[k]\n",
    "    for s in range(X.shape[0]):\n",
    "        if s == k: continue\n",
    "        avect2 = X[s]\n",
    "        if np.abs(avect1 - avect2).sum() <= 2:\n",
    "            bundle_graph[k,s] = 1.0\n",
    "            bundle_graph[s,k] = 1.0\n",
    "\n",
    "# temporal graph defining\n",
    "cycle = graph_utils.make_cycle(region_ftimecourse.shape[-1])\n",
    "\n",
    "Ls = graph_utils.compute_directed_laplacian(bundle_graph)\n",
    "Lt = graph_utils.compute_directed_laplacian(cycle)\n",
    "\n",
    "Xmult = np.array([Xp.T for _ in range(region_ftimecourse.shape[-1])])\n",
    "\n",
    "bundle_opt, logs = inpaint_utils.optimize_lreg(Xmult, region_ftimecourse, Ls=Ls, Lt=Lt, \n",
    "                                               verbose=True, num_epochs=200, logging=True, p1=0, p2=0, lr=1)\n",
    "\n",
    "save(f\"../resources/weights_regressors_activity/weighted_bundle_activity_timevertex{thresh_subjapp}_scale{scale}_stability-{perc}p_remove.pkl\", bundle_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microstruct_atlasing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
